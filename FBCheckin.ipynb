{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tri0 = location[location.place_id == location.place_id.unique()[0]]\n",
    "tri1 = location[location.place_id == location.place_id.unique()[1]]\n",
    "tri2 = location[location.place_id == location.place_id.unique()[2]]\n",
    "# %matplotlib inline\n",
    "# plt.scatter(tri0.x, tri0.y) # Mostly a single x, some scatter in y. Lots of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tri0_stats = tri0[['x', 'y', 'accuracy', 'time']].describe()\n",
    "\n",
    "# Compute outliers (by boxplot)\n",
    "# http://stackoverflow.com/questions/17725927/boxplots-in-matplotlib-markers-and-outliers\n",
    "IQR = tri0_stats.iloc[6] - tri0_stats.iloc[4]\n",
    "rng = tri0_stats.iloc[7] - tri0_stats.iloc[3]\n",
    "tri0_stats = tri0_stats.append(rng, ignore_index=True)\n",
    "tri0_stats = tri0_stats.append(IQR, ignore_index=True)\n",
    "out_min = tri0_stats.iloc[4] - IQR*1.5\n",
    "out_max = tri0_stats.iloc[6] + IQR*1.5\n",
    "tri0_stats = tri0_stats.append(out_min, ignore_index=True)\n",
    "tri0_stats = tri0_stats.append(out_max, ignore_index=True)\n",
    "\n",
    "tri0_stats.index = (['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'range', 'IQR', 'out_min', 'out_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR    0.002158\n",
      "Name: x, dtype: float64\n",
      "IQR    0.100506\n",
      "Name: y, dtype: float64\n",
      "IQR    0.593515\n",
      "Name: time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate IQR / range\n",
    "print tri0_stats[tri0_stats.index == 'IQR'].x / float(tri0_stats[tri0_stats.index == 'range'].x)\n",
    "print tri0_stats[tri0_stats.index == 'IQR'].y / float(tri0_stats[tri0_stats.index == 'range'].y)\n",
    "print tri0_stats[tri0_stats.index == 'IQR'].time / float(tri0_stats[tri0_stats.index == 'range'].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795564261168\n",
      "9.08097216495\n"
     ]
    }
   ],
   "source": [
    "# Compute for x\n",
    "sum(i > out_max.x for i in tri0.x) + sum(i < out_min.x for i in tri0.x) # 68\n",
    "tri0_bp_rmOLx = tri0[(tri0.x < out_max.x) & (tri0.x > out_min.x)]\n",
    "tri0_bp_rmOLx.shape # 585\n",
    "\n",
    "# Compute for y\n",
    "sum(i > out_max.y for i in tri0.y) + sum(i < out_min.y for i in tri0.y) # 13\n",
    "tri0_bp_rmOLy = tri0[(tri0.y < out_max.y) & (tri0.y > out_min.y)]\n",
    "tri0_bp_rmOLy.shape # 640\n",
    "\n",
    "# Compute for accuracy\n",
    "sum(i > out_max.accuracy for i in tri0.accuracy) + sum(i < out_min.accuracy for i in tri0.accuracy) # 135\n",
    "tri0_bp_rmOLacc = tri0[(tri0.accuracy < out_max.accuracy) & (tri0.accuracy > out_min.accuracy)]\n",
    "tri0_bp_rmOLacc.shape # 518\n",
    "\n",
    "sum(tri0_bp_rmOLx.row_id.isin(tri0_bp_rmOLy.row_id)) # 582 non-outliers in x and y overlap (89%)\n",
    "sum(tri0_bp_rmOLx.row_id.isin(tri0_bp_rmOLacc.row_id)) # 482 non-outliers in x and acc overlap (74%)\n",
    "sum(tri0_bp_rmOLy.row_id.isin(tri0_bp_rmOLacc.row_id)) # 509 non-outliers in y and acc overlap (78%)\n",
    "\n",
    "tri0_bp_rmOL = tri0_bp_rmOLx[(tri0_bp_rmOLx.y < out_max.y) & (tri0_bp_rmOLx.y > out_min.y)] \n",
    "\n",
    "x0_bp = tri0_bp_rmOL.x.mean()\n",
    "y0_bp = tri0_bp_rmOL.y.mean()\n",
    "print (x0_bp)\n",
    "print (y0_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(642, 6)\n",
      "(508, 6)\n",
      "(625, 6)\n",
      "0.798272189349\n",
      "9.0805122288\n"
     ]
    }
   ],
   "source": [
    "# Compute outliers (by stdev)\n",
    "sum(tri0.x > tri0.x.mean() + tri0.x.std()) + sum(tri0.x < tri0.x.mean() - tri0.x.std()) # 11 only\n",
    "tri0_std_rmOLx = tri0[(tri0.x < tri0.x.mean() + tri0.x.std()) & (tri0.x > tri0.x.mean() - tri0.x.std())]\n",
    "print tri0_std_rmOLx.shape # 642\n",
    "\n",
    "sum(tri0.y > tri0.y.mean() + tri0.y.std()) + sum(tri0.y < tri0.y.mean() - tri0.y.std()) # 145\n",
    "tri0_std_rmOLy = tri0[(tri0.y < tri0.y.mean() + tri0.y.std()) & (tri0.y > tri0.y.mean() - tri0.y.std())]\n",
    "print (tri0_std_rmOLy.shape) # 508\n",
    "\n",
    "tri0_std_rmOLacc = tri0[(tri0.accuracy < tri0.accuracy.mean() + tri0.accuracy.std()) & (tri0.accuracy > tri0.accuracy.mean() - tri0.accuracy.std())]\n",
    "print (tri0_std_rmOLacc.shape) # 625\n",
    "\n",
    "# Removed x and y outliers; 507 left\n",
    "tri0_std_rmOL = tri0_std_rmOLx[(tri0_std_rmOLx.y < tri0.y.mean() + tri0.y.std()) & (tri0_std_rmOLx.y > tri0.y.mean() - tri0.y.std())]\n",
    "\n",
    "x0_std = tri0_std_rmOL.x.mean()\n",
    "y0_std = tri0_std_rmOL.y.mean()\n",
    "print (x0_std)\n",
    "print (y0_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 46), (0, 35), (12, 35), (13, 35), (15, 35), (23, 35), (7, 34), (20, 32), (1, 31), (16, 31), (4, 29), (18, 29), (3, 27), (17, 26), (9, 24), (14, 23), (21, 23), (19, 22), (2, 19), (10, 18), (11, 18), (5, 16), (22, 16), (8, 14)]\n",
      "[(6, 46)]\n"
     ]
    }
   ],
   "source": [
    "tri0_stats.time\n",
    "\n",
    "import datetime\n",
    "a = pd.to_datetime(tri0.time, unit = 's')\n",
    "hr_of_day0 = []\n",
    "for i in a:\n",
    "    hr_of_day0.append(\n",
    "        datetime.datetime.strptime(str(i)[11:], \"%H:%M:%S\").hour\n",
    "    )\n",
    "from collections import Counter\n",
    "freq = Counter(hr_of_day0)\n",
    "print (freq.most_common())   # Returns all unique items and their counts\n",
    "print (freq.most_common(1))  # Returns the highest occurring item\n",
    "hrHiFreq0 = freq.most_common(1)\n",
    "hrHiFreq0 = freq.most_common()[0][0] # The hour of day where most check-ins took place\n",
    "hrLoFreq0 = freq.most_common()[len(freq.most_common())-1][0] # The hour of day where least check-ins took place\n",
    "hrMean0 = sum(i[1] for i in freq.most_common()) / float(len(freq.most_common())) # Average number of check-ins per h\n",
    "hrStd0 = (sum((i[1]-hrMean0)**2 for i in freq.most_common()) / float(len(freq.most_common())))**(1/2.0) # How different were the checks of 1 h from another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f2151fbfd96b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# location.groupby('place_id')['x'].quantile(0.25)[:3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#location.groupby('place_id')['x'][]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'place_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'place_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IQR_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yingjiang/miniconda2/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/Users/yingjiang/miniconda2/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# location.groupby('place_id')['x'].quantile(0.25)[:3]\n",
    "#location.groupby('place_id')['x'][]\n",
    "type(location.groupby('place_id')['x'] > outmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location.groupby('place_id')['x'].quantile(0.75)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1['place_id'] = location.place_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1['IQR_x'] = location.groupby('place_id')['x'].quantile(0.75) - location.groupby('place_id')['x'].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns = ['place_id',\n",
    "#            'IQR_x', 'IQR_y', 'IQR_acc', 'IQR_time',\n",
    "#            'Range_x', 'Range_y', 'Range_acc', 'Range_time',\n",
    "#            'IQRRatio_x', 'IQRRatio_y', 'IQRRatio_acc', 'IQRRatio_time',\n",
    "#            'numOLBP_x', 'numOLBP_y', 'numOLBP_acc', 'numOLBP_time', \n",
    "#            'numOLStd_x', 'numOLStd_y', 'numOLStd_acc', 'numOLStd_time', \n",
    "#            'meanBP_x', 'stdBP_x', 'meanBP_y', 'stdBP_y',\n",
    "#            'meanStd_x', 'stdStd_x', 'meanStd_y', 'stdStd_y',\n",
    "#            'hr_HiFreq', 'hr_LoFreq', 'hr_Mean', 'hr_Std'\n",
    "#           ]\n",
    "\n",
    "f1['IQR_y'] = location.groupby('place_id')['y'].quantile(0.75) - location.groupby('place_id')['y'].quantile(0.25)\n",
    "f1['IQR_acc'] = location.groupby('place_id')['accuracy'].quantile(0.75) - location.groupby('place_id')['accuracy'].quantile(0.25)\n",
    "f1['IQR_time'] = location.groupby('place_id')['time'].quantile(0.75) - location.groupby('place_id')['time'].quantile(0.25)\n",
    "\n",
    "f1['Range_x'] = location.groupby('place_id')['x'].max() - location.groupby('place_id')['x'].min()\n",
    "f1['Range_y'] = location.groupby('place_id')['y'].max() - location.groupby('place_id')['y'].min()\n",
    "f1['Range_acc'] = location.groupby('place_id')['accuracy'].max() - location.groupby('place_id')['accuracy'].min()\n",
    "f1['Range_time'] = location.groupby('place_id')['time'].max() - location.groupby('place_id')['time'].min()\n",
    "\n",
    "f1['IQRRatio_x'] = f1['IQR_x'] / f1['Range_x']\n",
    "f1['IQRRatio_y'] = location.groupby('place_id')['y'].max() - location.groupby('place_id')['y'].min()\n",
    "f1['IQRRatio_acc'] = location.groupby('place_id')['accuracy'].max() - location.groupby('place_id')['accuracy'].min()\n",
    "f1['IQRRatio_time'] = location.groupby('place_id')['time'].max() - location.groupby('place_id')['time'].min()\n",
    "\n",
    "f1['out_max'] = location.groupby('place_id')['x'].quantile(0.75) + f1['IQR_x']*1.5\n",
    "f1['out_min'] = location.groupby('place_id')['x'].quantile(0.25) - f1['IQR_x']*1.5\n",
    "# f1['numOLBP_x'] = location.groupby('place_id')['x'][(location.groupby('place_id')['x'] > location.groupby('place_id')['x'].quantile(0.75) + f1['IQR_x']*1.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tri0 = location[location.place_id == 1000015801]\n",
    "# tri1 = location[location.place_id == 1000017288]\n",
    "# tri2 = location[location.place_id == 1000025138]\n",
    "# tri0.x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tri0Stats = getStats(tri0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st computation took:  0.0025680065155\n",
      "2nd computation took:  0.0898871421814\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "tri0.x.loc[tri0['x'] > float(tri0Stats[tri0Stats.index == 'out_max'].x)].count() + tri0.x.loc[tri0['x'] < float(tri0Stats[tri0Stats.index == 'out_min'].x)].count()\n",
    "t1 = time.time()\n",
    "print '1st computation took: ', t1 - t0\n",
    "sum(i > float(tri0Stats[tri0Stats.index == 'out_max'].x) for i in tri0.x) + sum(i < float(tri0Stats[tri0Stats.index == 'out_min'].x) for i in tri0.x)\n",
    "t2 = time.time()\n",
    "print '2nd computation took: ', t2 - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# path = os.getcwd()\n",
    "# os.listdir(path)\n",
    "# location = pd.read_csv(path + '/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getLoc(n, data):\n",
    "    return data[data.place_id == data.place_id.unique()[n]]\n",
    "\n",
    "def getStats(locData):\n",
    "    locDataStats = locData[['x', 'y', 'accuracy', 'time']].describe()\n",
    "    IQR = locDataStats.iloc[6] - locDataStats.iloc[4]\n",
    "    rng = locDataStats.iloc[7] - locDataStats.iloc[3]\n",
    "    locDataStats = locDataStats.append(rng, ignore_index=True)\n",
    "    locDataStats = locDataStats.append(IQR, ignore_index=True)\n",
    "    out_min = locDataStats.iloc[4] - IQR*1.5\n",
    "    out_max = locDataStats.iloc[6] + IQR*1.5\n",
    "    locDataStats = locDataStats.append(out_min, ignore_index=True)\n",
    "    locDataStats = locDataStats.append(out_max, ignore_index=True)\n",
    "    locDataStats.index = (['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'range', 'IQR', 'out_min', 'out_max'])\n",
    "    return locDataStats\n",
    "\n",
    "def getIQR(locDataStats):\n",
    "    IQR = [locDataStats[locDataStats.index == 'IQR'].x,\n",
    "           locDataStats[locDataStats.index == 'IQR'].y,\n",
    "           locDataStats[locDataStats.index == 'IQR'].accuracy,\n",
    "           locDataStats[locDataStats.index == 'IQR'].time]\n",
    "    rng = [locDataStats[locDataStats.index == 'range'].x,\n",
    "           locDataStats[locDataStats.index == 'range'].y,\n",
    "           locDataStats[locDataStats.index == 'range'].accuracy,\n",
    "           locDataStats[locDataStats.index == 'range'].time]\n",
    "    IQRRatio = [locDataStats[locDataStats.index == 'IQR'].x / float(locDataStats[locDataStats.index == 'range'].x),\n",
    "                locDataStats[locDataStats.index == 'IQR'].y / float(locDataStats[locDataStats.index == 'range'].y),\n",
    "                locDataStats[locDataStats.index == 'IQR'].accuracy / float(locDataStats[locDataStats.index == 'range'].accuracy),\n",
    "                locDataStats[locDataStats.index == 'IQR'].time / float(locDataStats[locDataStats.index == 'range'].time)]\n",
    "    return [IQR, rng, IQRRatio]\n",
    "\n",
    "def getNumOutliersBP(locDataStats, locData):\n",
    "#     ol_BPx = sum(i > float(locDataStats[locDataStats.index == 'out_max'].x) for i in locData.x) + sum(i < float(locDataStats[locDataStats.index == 'out_min'].x) for i in locData.x)\n",
    "#     ol_BPy = sum(i > float(locDataStats[locDataStats.index == 'out_max'].y) for i in locData.y) + sum(i < float(locDataStats[locDataStats.index == 'out_min'].y) for i in locData.y)\n",
    "#     ol_BPacc = sum(i > float(locDataStats[locDataStats.index == 'out_max'].accuracy) for i in locData.accuracy) + sum(i < float(locDataStats[locDataStats.index == 'out_min'].accuracy) for i in locData.accuracy)\n",
    "#     ol_BPtime = sum(i > float(locDataStats[locDataStats.index == 'out_max'].time) for i in locData.time) + sum(i < float(locDataStats[locDataStats.index == 'out_min'].time) for i in locData.time)\n",
    "\n",
    "    ol_BPx = locData.x.loc[locData['x'] > float(locDataStats[locDataStats.index == 'out_max'].x)].count() + locData.x.loc[locData['x'] < float(locDataStats[locDataStats.index == 'out_min'].x)].count()\n",
    "    ol_BPy = locData.y.loc[locData['y'] > float(locDataStats[locDataStats.index == 'out_max'].y)].count() + locData.y.loc[locData['y'] < float(locDataStats[locDataStats.index == 'out_min'].y)].count()\n",
    "    ol_BPacc = locData.accuracy.loc[locData['accuracy'] > float(locDataStats[locDataStats.index == 'out_max'].accuracy)].count() + locData.accuracy.loc[locData['accuracy'] < float(locDataStats[locDataStats.index == 'out_min'].accuracy)].count()\n",
    "    ol_BPtime = locData.time.loc[locData['time'] > float(locDataStats[locDataStats.index == 'out_max'].time)].count() + locData.time.loc[locData['time'] < float(locDataStats[locDataStats.index == 'out_min'].time)].count()\n",
    "\n",
    "    return [ol_BPx, ol_BPy, ol_BPacc, ol_BPtime]\n",
    "\n",
    "def getNumOutliersStd(locData):\n",
    "#     ol_Stdx = sum(locData.x > locData.x.mean() + locData.x.std()) + sum(locData.x < locData.x.mean() - locData.x.std())\n",
    "#     ol_Stdy = sum(locData.y > locData.y.mean() + locData.y.std()) + sum(locData.y < locData.y.mean() - locData.y.std())\n",
    "#     ol_Stdacc = sum(locData.accuracy > locData.accuracy.mean() + locData.accuracy.std()) + sum(locData.accuracy < locData.accuracy.mean() - locData.accuracy.std())\n",
    "#     ol_Stdtime = sum(locData.time > locData.time.mean() + locData.time.std()) + sum(locData.time < locData.time.mean() - locData.time.std())\n",
    "\n",
    "    ol_Stdx = locData.x.loc[locData.x > locData.x.mean() + locData.x.std()].count() + locData.x.loc[locData.x < locData.x.mean() - locData.x.std()].count()\n",
    "    ol_Stdy = locData.y.loc[locData.y > locData.y.mean() + locData.y.std()].count() + locData.y.loc[locData.y < locData.y.mean() - locData.y.std()].count()\n",
    "    ol_Stdacc = locData.accuracy.loc[locData.accuracy > locData.accuracy.mean() + locData.accuracy.std()].count() + locData.accuracy.loc[locData.accuracy < locData.accuracy.mean() - locData.accuracy.std()].count()\n",
    "    ol_Stdtime = locData.time.loc[locData.time > locData.time.mean() + locData.time.std()].count() + locData.time.loc[locData.time < locData.time.mean() - locData.time.std()].count()\n",
    "\n",
    "    return [ol_Stdx, ol_Stdy, ol_Stdacc, ol_Stdtime]\n",
    "\n",
    "def rmOutliersBPxy(locDataStats, locData):\n",
    "    locData_bp_rmOLx = locData[(locData.x < float(locDataStats[locDataStats.index == 'out_max'].x)) & (locData.x > float(locDataStats[locDataStats.index == 'out_min'].x))]\n",
    "    locData_bp_rmOL = locData_bp_rmOLx[(locData_bp_rmOLx.y < float(locDataStats[locDataStats.index == 'out_max'].y)) & (locData_bp_rmOLx.y > float(locDataStats[locDataStats.index == 'out_min'].y))]\n",
    "    return locData_bp_rmOL\n",
    "\n",
    "def rmOutliersStdxy(locData):\n",
    "    locData_std_rmOLx = locData[(locData.x < locData.x.mean() + locData.x.std()) & (locData.x > locData.x.mean() - locData.x.std())]\n",
    "    locData_std_rmOL = locData_std_rmOLx[(locData_std_rmOLx.y < locData.y.mean() + locData.y.std()) & (locData_std_rmOLx.y > locData.y.mean() - locData.y.std())]\n",
    "    return locData_std_rmOL\n",
    "\n",
    "def getMeanBPxy(locDataStats, locData):\n",
    "    locData_rmOLBP = rmOutliersBPxy(locDataStats, locData)    \n",
    "    return [locData_rmOLBP.x.mean(), locData_rmOLBP.x.std(), locData_rmOLBP.y.mean(), locData_rmOLBP.y.std()]\n",
    "\n",
    "def getMeanStdxy(locData):\n",
    "    locData_rmOLStd = rmOutliersStdxy(locData)\n",
    "    return [locData_rmOLStd.x.mean(), locData_rmOLStd.x.std(), locData_rmOLStd.y.mean(), locData_rmOLStd.y.std()]\n",
    "\n",
    "def getFreqTime(locData):\n",
    "    import datetime\n",
    "    from collections import Counter\n",
    "    hr_of_day0 = []\n",
    "    for i in pd.to_datetime(locData.time, unit = 's'):\n",
    "        hr_of_day0.append(\n",
    "            datetime.datetime.strptime(str(i)[11:], \"%H:%M:%S\").hour\n",
    "        )\n",
    "    freq = Counter(hr_of_day0)\n",
    "    hrHiFreq = freq.most_common()[0][0] # The hour of day where most check-ins took place\n",
    "    hrLoFreq = freq.most_common()[len(freq.most_common())-1][0] # The hour of day where least check-ins took place\n",
    "    hrMean = sum(i[1] for i in freq.most_common()) / float(len(freq.most_common())) # Average number of check-ins per h\n",
    "    hrStd = (sum((i[1]-hrMean)**2 for i in freq.most_common()) / float(len(freq.most_common())))**(1/2.0) # How different were the checks of 1 h from another\n",
    "    return [hrHiFreq, hrLoFreq, hrMean, hrStd]\n",
    "\n",
    "def getFreqDay(locData):\n",
    "    day_of_wk0 = [i.dayofweek for i in pd.to_datetime(locData.time, unit = 's')]\n",
    "    freq = Counter(day_of_wk0)\n",
    "    wkHiFreq = freq.most_common()[0][0] # The hour of day where most check-ins took place\n",
    "    wkLoFreq = freq.most_common()[len(freq.most_common())-1][0] # The hour of day where least check-ins took place\n",
    "    is_wkend = np.where((np.asarray(day_of_wk0)==5) | (np.asarray(day_of_wk0)==6), 1, 0)\n",
    "    not_wkend = np.where((np.asarray(day_of_wk0)==5) | (np.asarray(day_of_wk0)==6), 0, 1)\n",
    "    # wkendRatio = is_wkend.sum() / float(len(day_of_wk0))\n",
    "    wkendRatio = (is_wkend.sum()/2.0) / (not_wkend.sum()/5.0)\n",
    "    return [wkHiFreq, wkLoFreq, wkendRatio]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91100\n",
      "Number of data points collected:  52\n",
      "91200\n",
      "Number of data points collected:  152\n",
      "91300\n",
      "Number of data points collected:  252\n",
      "91400\n",
      "Number of data points collected:  352\n",
      "91500\n",
      "Number of data points collected:  452\n",
      "91600\n",
      "Number of data points collected:  552\n",
      "91700\n",
      "Number of data points collected:  652\n",
      "91800\n",
      "Number of data points collected:  752\n",
      "91900\n",
      "Number of data points collected:  852\n",
      "92000\n",
      "Number of data points collected:  952\n",
      "92100\n",
      "Number of data points collected:  1052\n",
      "92200\n",
      "Number of data points collected:  1152\n",
      "92300\n",
      "Number of data points collected:  1252\n",
      "92400\n",
      "Number of data points collected:  1352\n",
      "92500\n",
      "Number of data points collected:  1452\n",
      "92600\n",
      "Number of data points collected:  1552\n",
      "92700\n",
      "Number of data points collected:  1652\n",
      "92800\n",
      "Number of data points collected:  1752\n",
      "92900\n",
      "Number of data points collected:  1852\n",
      "93000\n",
      "Number of data points collected:  1952\n",
      "93100\n",
      "Number of data points collected:  2052\n",
      "93200\n",
      "Number of data points collected:  2152\n",
      "93300\n",
      "Number of data points collected:  2252\n",
      "93400\n",
      "Number of data points collected:  2352\n",
      "93500\n",
      "Number of data points collected:  2452\n",
      "93600\n",
      "Number of data points collected:  2552\n",
      "93700\n",
      "Number of data points collected:  2652\n",
      "93800\n",
      "Number of data points collected:  2752\n",
      "93900\n",
      "Number of data points collected:  2852\n",
      "94000\n",
      "Number of data points collected:  2952\n",
      "94100\n",
      "Number of data points collected:  3052\n",
      "94200\n",
      "Number of data points collected:  3152\n",
      "94300\n",
      "Number of data points collected:  3252\n",
      "94400\n",
      "Number of data points collected:  3352\n",
      "94500\n",
      "Number of data points collected:  3452\n",
      "94600\n",
      "Number of data points collected:  3552\n",
      "94700\n",
      "Number of data points collected:  3652\n",
      "94800\n",
      "Number of data points collected:  3752\n",
      "94900\n",
      "Number of data points collected:  3852\n",
      "95000\n",
      "Number of data points collected:  3952\n",
      "95100\n",
      "Number of data points collected:  4052\n",
      "95200\n",
      "Number of data points collected:  4152\n",
      "95300\n",
      "Number of data points collected:  4252\n",
      "95400\n",
      "Number of data points collected:  4352\n",
      "95500\n",
      "Number of data points collected:  4452\n",
      "95600\n",
      "Number of data points collected:  4552\n",
      "95700\n",
      "Number of data points collected:  4652\n",
      "95800\n",
      "Number of data points collected:  4752\n",
      "95900\n",
      "Number of data points collected:  4852\n",
      "96000\n",
      "Number of data points collected:  4952\n",
      "96100\n",
      "Number of data points collected:  5052\n",
      "96200\n",
      "Number of data points collected:  5152\n",
      "96300\n",
      "Number of data points collected:  5252\n",
      "96400\n",
      "Number of data points collected:  5352\n",
      "96500\n",
      "Number of data points collected:  5452\n",
      "96600\n",
      "Number of data points collected:  5552\n",
      "96700\n",
      "Number of data points collected:  5652\n",
      "96800\n",
      "Number of data points collected:  5752\n",
      "96900\n",
      "Number of data points collected:  5852\n",
      "97000\n",
      "Number of data points collected:  5952\n",
      "97100\n",
      "Number of data points collected:  6052\n",
      "97200\n",
      "Number of data points collected:  6152\n",
      "97300\n",
      "Number of data points collected:  6252\n",
      "97400\n",
      "Number of data points collected:  6352\n",
      "97500\n",
      "Number of data points collected:  6452\n",
      "97600\n",
      "Number of data points collected:  6552\n",
      "97700\n",
      "Number of data points collected:  6652\n",
      "97800\n",
      "Number of data points collected:  6752\n",
      "97900\n",
      "Number of data points collected:  6852\n",
      "98000\n",
      "Number of data points collected:  6952\n",
      "98100\n",
      "Number of data points collected:  7052\n",
      "98200\n",
      "Number of data points collected:  7152\n",
      "98300\n",
      "Number of data points collected:  7252\n",
      "98400\n",
      "Number of data points collected:  7352\n",
      "98500\n",
      "Number of data points collected:  7452\n",
      "98600\n",
      "Number of data points collected:  7552\n",
      "98700\n",
      "Number of data points collected:  7652\n",
      "98800\n",
      "Number of data points collected:  7752\n",
      "98900\n",
      "Number of data points collected:  7852\n",
      "99000\n",
      "Number of data points collected:  7952\n",
      "99100\n",
      "Number of data points collected:  8052\n",
      "99200\n",
      "Number of data points collected:  8152\n",
      "99300\n",
      "Number of data points collected:  8252\n",
      "99400\n",
      "Number of data points collected:  8352\n",
      "99500\n",
      "Number of data points collected:  8452\n",
      "99600\n",
      "Number of data points collected:  8552\n",
      "99700\n",
      "Number of data points collected:  8652\n",
      "99800\n",
      "Number of data points collected:  8752\n",
      "99900\n",
      "Number of data points collected:  8852\n",
      "100000\n",
      "Number of data points collected:  8952\n",
      "100100\n",
      "Number of data points collected:  9052\n",
      "100200\n",
      "Number of data points collected:  9152\n",
      "100300\n",
      "Number of data points collected:  9252\n",
      "100400\n",
      "Number of data points collected:  9352\n",
      "100500\n",
      "Number of data points collected:  9452\n",
      "100600\n",
      "Number of data points collected:  9552\n",
      "100700\n",
      "Number of data points collected:  9652\n",
      "100800\n",
      "Number of data points collected:  9752\n",
      "100900\n",
      "Number of data points collected:  9852\n",
      "101000\n",
      "Number of data points collected:  9952\n",
      "101100\n",
      "Number of data points collected:  10052\n",
      "101200\n",
      "Number of data points collected:  10152\n",
      "101300\n",
      "Number of data points collected:  10252\n",
      "101400\n",
      "Number of data points collected:  10352\n",
      "101500\n",
      "Number of data points collected:  10452\n",
      "101600\n",
      "Number of data points collected:  10552\n",
      "101700\n",
      "Number of data points collected:  10652\n",
      "101800\n",
      "Number of data points collected:  10752\n",
      "101900\n",
      "Number of data points collected:  10852\n",
      "102000\n",
      "Number of data points collected:  10952\n",
      "102100\n",
      "Number of data points collected:  11052\n",
      "102200\n",
      "Number of data points collected:  11152\n",
      "102300\n",
      "Number of data points collected:  11252\n",
      "102400\n",
      "Number of data points collected:  11352\n",
      "102500\n",
      "Number of data points collected:  11452\n",
      "102600\n",
      "Number of data points collected:  11552\n",
      "102700\n",
      "Number of data points collected:  11652\n",
      "102800\n",
      "Number of data points collected:  11752\n",
      "102900\n",
      "Number of data points collected:  11852\n",
      "103000\n",
      "Number of data points collected:  11952\n",
      "103100\n",
      "Number of data points collected:  12052\n",
      "103200\n",
      "Number of data points collected:  12152\n",
      "103300\n",
      "Number of data points collected:  12252\n",
      "103400\n",
      "Number of data points collected:  12352\n",
      "103500\n",
      "Number of data points collected:  12452\n",
      "103600\n",
      "Number of data points collected:  12552\n",
      "103700\n",
      "Number of data points collected:  12652\n",
      "103800\n",
      "Number of data points collected:  12752\n",
      "103900\n",
      "Number of data points collected:  12852\n",
      "104000\n",
      "Number of data points collected:  12952\n",
      "104100\n",
      "Number of data points collected:  13052\n",
      "104200\n",
      "Number of data points collected:  13152\n",
      "104300\n",
      "Number of data points collected:  13252\n",
      "104400\n",
      "Number of data points collected:  13352\n",
      "104500\n",
      "Number of data points collected:  13452\n",
      "104600\n",
      "Number of data points collected:  13552\n",
      "104700\n",
      "Number of data points collected:  13652\n",
      "104800\n",
      "Number of data points collected:  13752\n",
      "104900\n",
      "Number of data points collected:  13852\n",
      "105000\n",
      "Number of data points collected:  13952\n",
      "105100\n",
      "Number of data points collected:  14052\n",
      "105200\n",
      "Number of data points collected:  14152\n",
      "105300\n",
      "Number of data points collected:  14252\n",
      "105400\n",
      "Number of data points collected:  14352\n",
      "105500\n",
      "Number of data points collected:  14452\n",
      "105600\n",
      "Number of data points collected:  14552\n",
      "105700\n",
      "Number of data points collected:  14652\n",
      "105800\n",
      "Number of data points collected:  14752\n",
      "105900\n",
      "Number of data points collected:  14852\n",
      "106000\n",
      "Number of data points collected:  14952\n",
      "106100\n",
      "Number of data points collected:  15052\n",
      "106200\n",
      "Number of data points collected:  15152\n",
      "106300\n",
      "Number of data points collected:  15252\n",
      "106400\n",
      "Number of data points collected:  15352\n",
      "106500\n",
      "Number of data points collected:  15452\n",
      "106600\n",
      "Number of data points collected:  15552\n",
      "106700\n",
      "Number of data points collected:  15652\n",
      "106800\n",
      "Number of data points collected:  15752\n",
      "106900\n",
      "Number of data points collected:  15852\n",
      "107000\n",
      "Number of data points collected:  15952\n",
      "107100\n",
      "Number of data points collected:  16052\n",
      "107200\n",
      "Number of data points collected:  16152\n",
      "107300\n",
      "Number of data points collected:  16252\n",
      "107400\n",
      "Number of data points collected:  16352\n",
      "107500\n",
      "Number of data points collected:  16452\n",
      "107600\n",
      "Number of data points collected:  16552\n",
      "107700\n",
      "Number of data points collected:  16652\n",
      "107800\n",
      "Number of data points collected:  16752\n",
      "107900\n",
      "Number of data points collected:  16852\n",
      "108000\n",
      "Number of data points collected:  16952\n",
      "108100\n",
      "Number of data points collected:  17052\n",
      "108200\n",
      "Number of data points collected:  17152\n",
      "108300\n",
      "Number of data points collected:  17252\n"
     ]
    }
   ],
   "source": [
    "# tmpAll = []\n",
    "for i in range(len(location.place_id.unique()))[91073:]:\n",
    "    tmp = []\n",
    "    tmp.append(int(location.place_id.unique()[i])) # len(tmp) = 1\n",
    "    loc = getLoc(n = i, data = location)\n",
    "    locStats = getStats(loc)\n",
    "    \n",
    "    for m in getIQR(locStats): # 3 lists of 4 elements each.\n",
    "        for n in m: # 4 elements\n",
    "            tmp.append(n.values[0]) # len(tmp) = 13\n",
    "\n",
    "    tmp.extend(getNumOutliersBP(locStats, loc)) # len(tmp) = 17\n",
    "    tmp.extend(getNumOutliersStd(loc)) # len(tmp) = 21\n",
    "\n",
    "    tmp.extend(getMeanBPxy(locStats, loc)) # len(tmp) = 25\n",
    "    tmp.extend(getMeanStdxy(loc)) # len(tmp) = 29\n",
    "    \n",
    "    tmp.extend(getFreqTime(loc)) # len(tmp) = 33\n",
    "    tmpAll.append(tmp)\n",
    "    if i % 100 == 0:\n",
    "        print i\n",
    "        print 'Number of data points collected: ', len(tmpAll)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17341, 33)\n"
     ]
    }
   ],
   "source": [
    "columns = ['place_id',\n",
    "           'IQR_x', 'IQR_y', 'IQR_acc', 'IQR_time',\n",
    "           'Range_x', 'Range_y', 'Range_acc', 'Range_time',\n",
    "           'IQRRatio_x', 'IQRRatio_y', 'IQRRatio_acc', 'IQRRatio_time',\n",
    "           'numOLBP_x', 'numOLBP_y', 'numOLBP_acc', 'numOLBP_time', \n",
    "           'numOLStd_x', 'numOLStd_y', 'numOLStd_acc', 'numOLStd_time', \n",
    "           'meanBP_x', 'stdBP_x', 'meanBP_y', 'stdBP_y',\n",
    "           'meanStd_x', 'stdStd_x', 'meanStd_y', 'stdStd_y',\n",
    "           'hr_HiFreq', 'hr_LoFreq', 'hr_Mean', 'hr_Std'\n",
    "          ]\n",
    "\n",
    "features4 = pd.DataFrame(tmpAll, columns = columns)\n",
    "print features4.shape\n",
    "pickle.dump(features4, open('features4.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Number of data points collected:  1\n",
      "100\n",
      "Number of data points collected:  101\n",
      "200\n",
      "Number of data points collected:  201\n",
      "300\n",
      "Number of data points collected:  301\n",
      "400\n",
      "Number of data points collected:  401\n",
      "500\n",
      "Number of data points collected:  501\n",
      "600\n",
      "Number of data points collected:  601\n",
      "700\n",
      "Number of data points collected:  701\n",
      "800\n",
      "Number of data points collected:  801\n",
      "900\n",
      "Number of data points collected:  901\n",
      "1000\n",
      "Number of data points collected:  1001\n",
      "1100\n",
      "Number of data points collected:  1101\n",
      "1200\n",
      "Number of data points collected:  1201\n",
      "1300\n",
      "Number of data points collected:  1301\n",
      "1400\n",
      "Number of data points collected:  1401\n",
      "1500\n",
      "Number of data points collected:  1501\n",
      "1600\n",
      "Number of data points collected:  1601\n",
      "1700\n",
      "Number of data points collected:  1701\n",
      "1800\n",
      "Number of data points collected:  1801\n",
      "1900\n",
      "Number of data points collected:  1901\n",
      "2000\n",
      "Number of data points collected:  2001\n",
      "2100\n",
      "Number of data points collected:  2101\n",
      "2200\n",
      "Number of data points collected:  2201\n",
      "2300\n",
      "Number of data points collected:  2301\n",
      "2400\n",
      "Number of data points collected:  2401\n",
      "2500\n",
      "Number of data points collected:  2501\n",
      "2600\n",
      "Number of data points collected:  2601\n",
      "2700\n",
      "Number of data points collected:  2701\n",
      "2800\n",
      "Number of data points collected:  2801\n",
      "2900\n",
      "Number of data points collected:  2901\n",
      "3000\n",
      "Number of data points collected:  3001\n",
      "3100\n",
      "Number of data points collected:  3101\n",
      "3200\n",
      "Number of data points collected:  3201\n",
      "3300\n",
      "Number of data points collected:  3301\n",
      "3400\n",
      "Number of data points collected:  3401\n",
      "3500\n",
      "Number of data points collected:  3501\n",
      "3600\n",
      "Number of data points collected:  3601\n",
      "3700\n",
      "Number of data points collected:  3701\n",
      "3800\n",
      "Number of data points collected:  3801\n",
      "3900\n",
      "Number of data points collected:  3901\n",
      "4000\n",
      "Number of data points collected:  4001\n",
      "4100\n",
      "Number of data points collected:  4101\n",
      "4200\n",
      "Number of data points collected:  4201\n",
      "4300\n",
      "Number of data points collected:  4301\n",
      "4400\n",
      "Number of data points collected:  4401\n",
      "4500\n",
      "Number of data points collected:  4501\n",
      "4600\n",
      "Number of data points collected:  4601\n",
      "4700\n",
      "Number of data points collected:  4701\n",
      "4800\n",
      "Number of data points collected:  4801\n",
      "4900\n",
      "Number of data points collected:  4901\n",
      "5000\n",
      "Number of data points collected:  5001\n",
      "5100\n",
      "Number of data points collected:  5101\n",
      "5200\n",
      "Number of data points collected:  5201\n",
      "5300\n",
      "Number of data points collected:  5301\n",
      "5400\n",
      "Number of data points collected:  5401\n",
      "5500\n",
      "Number of data points collected:  5501\n",
      "5600\n",
      "Number of data points collected:  5601\n",
      "5700\n",
      "Number of data points collected:  5701\n",
      "5800\n",
      "Number of data points collected:  5801\n",
      "5900\n",
      "Number of data points collected:  5901\n",
      "6000\n",
      "Number of data points collected:  6001\n",
      "6100\n",
      "Number of data points collected:  6101\n",
      "6200\n",
      "Number of data points collected:  6201\n",
      "6300\n",
      "Number of data points collected:  6301\n",
      "6400\n",
      "Number of data points collected:  6401\n",
      "6500\n",
      "Number of data points collected:  6501\n",
      "6600\n",
      "Number of data points collected:  6601\n",
      "6700\n",
      "Number of data points collected:  6701\n",
      "6800\n",
      "Number of data points collected:  6801\n",
      "6900\n",
      "Number of data points collected:  6901\n",
      "7000\n",
      "Number of data points collected:  7001\n",
      "7100\n",
      "Number of data points collected:  7101\n",
      "7200\n",
      "Number of data points collected:  7201\n",
      "7300\n",
      "Number of data points collected:  7301\n",
      "7400\n",
      "Number of data points collected:  7401\n",
      "7500\n",
      "Number of data points collected:  7501\n",
      "7600\n",
      "Number of data points collected:  7601\n",
      "7700\n",
      "Number of data points collected:  7701\n",
      "7800\n",
      "Number of data points collected:  7801\n",
      "7900\n",
      "Number of data points collected:  7901\n",
      "8000\n",
      "Number of data points collected:  8001\n",
      "8100\n",
      "Number of data points collected:  8101\n",
      "8200\n",
      "Number of data points collected:  8201\n",
      "8300\n",
      "Number of data points collected:  8301\n",
      "8400\n",
      "Number of data points collected:  8401\n",
      "8500\n",
      "Number of data points collected:  8501\n",
      "8600\n",
      "Number of data points collected:  8601\n",
      "8700\n",
      "Number of data points collected:  8701\n",
      "8800\n",
      "Number of data points collected:  8801\n",
      "8900\n",
      "Number of data points collected:  8901\n",
      "9000\n",
      "Number of data points collected:  9001\n",
      "9100\n",
      "Number of data points collected:  9101\n",
      "9200\n",
      "Number of data points collected:  9201\n",
      "9300\n",
      "Number of data points collected:  9301\n",
      "9400\n",
      "Number of data points collected:  9401\n",
      "9500\n",
      "Number of data points collected:  9501\n",
      "9600\n",
      "Number of data points collected:  9601\n",
      "9700\n",
      "Number of data points collected:  9701\n",
      "9800\n",
      "Number of data points collected:  9801\n",
      "9900\n",
      "Number of data points collected:  9901\n",
      "10000\n",
      "Number of data points collected:  10001\n",
      "10100\n",
      "Number of data points collected:  10101\n",
      "10200\n",
      "Number of data points collected:  10201\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-c575d37732fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetFreqDay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtmpAll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-a6bc515245ef>\u001b[0m in \u001b[0;36mgetLoc\u001b[0;34m(n, data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetLoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlocDataStats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingjiang/miniconda2/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingjiang/miniconda2/lib/python2.7/site-packages/pandas/core/nanops.pyc\u001b[0m in \u001b[0;36munique1d\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt64HashTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ensure_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyObjectHashTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmpAll = []\n",
    "for i in range(len(location.place_id.unique())):\n",
    "    tmp = []\n",
    "    loc = getLoc(n = i, data = location)\n",
    "    tmp.extend(getFreqDay(loc))\n",
    "    tmpAll.append(tmp)\n",
    "    if i % 100 == 0:\n",
    "        print i\n",
    "        print 'Number of data points collected: ', len(tmpAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10247\n",
      "10247\n"
     ]
    }
   ],
   "source": [
    "print i\n",
    "print len(tmpAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10247, 3)\n"
     ]
    }
   ],
   "source": [
    "columns_pt2 = ['wkHiFreq', 'wkLoFreq', 'wkendRatio']\n",
    "features_pt2 = pd.DataFrame(tmpAll, columns = columns_pt2)\n",
    "print features_pt2.shape\n",
    "pickle.dump(features_pt2, open('features_pt2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use groupby to get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yingjiang/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "locSmall = location.iloc[:10000, :]\n",
    "\n",
    "locSmall['timeFmtted'] = pd.to_datetime(locSmall.time, unit = 'm')\n",
    "\n",
    "extractHr = lambda x: datetime.datetime.strptime(str(x)[11:], \"%H:%M:%S\").hour\n",
    "locSmall['hour'] = locSmall.timeFmtted.apply(extractHr)\n",
    "\n",
    "extractDay = lambda x: x.dayofweek\n",
    "locSmall['weekday'] = locSmall.timeFmtted.apply(extractDay)\n",
    "\n",
    "locSmall['isWeekend'] = np.where((locSmall['weekday']==5) | (locSmall['weekday']==6), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locSmallG = pd.DataFrame()\n",
    "locSmallG['hrHiFreq'] = locSmall.groupby('place_id')['hour'].agg(lambda x: x.value_counts().index[0])\n",
    "locSmallG['hrLoFreq'] = locSmall.groupby('place_id')['hour'].agg(lambda x: x.value_counts().index[-1])\n",
    "locSmallG['dayHiFreq'] = locSmall.groupby('place_id')['weekday'].agg(lambda x: x.value_counts().index[0])\n",
    "locSmallG['dayLoFreq'] = locSmall.groupby('place_id')['weekday'].agg(lambda x: x.value_counts().index[-1])\n",
    "locSmallG['wkendRatio'] = locSmall.groupby('place_id')['isWeekend'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Groupby scale up\n",
    "\n",
    "location['timeFmtted'] = pd.to_datetime(location.time, unit = 'm')\n",
    "\n",
    "extractHr = lambda x: datetime.datetime.strptime(str(x)[11:], \"%H:%M:%S\").hour\n",
    "location['hour'] = location.timeFmtted.apply(extractHr)\n",
    "\n",
    "extractDay = lambda x: x.dayofweek\n",
    "location['weekday'] = location.timeFmtted.apply(extractDay)\n",
    "\n",
    "location['isWeekend'] = np.where((location['weekday']==5) | (location['weekday']==6), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locationG = pd.DataFrame()\n",
    "locationG['hrHiFreq'] = location.groupby('place_id')['hour'].agg(lambda x: x.value_counts().index[0])\n",
    "locationG['hrLoFreq'] = location.groupby('place_id')['hour'].agg(lambda x: x.value_counts().index[-1])\n",
    "locationG['dayHiFreq'] = location.groupby('place_id')['weekday'].agg(lambda x: x.value_counts().index[0])\n",
    "locationG['dayLoFreq'] = location.groupby('place_id')['weekday'].agg(lambda x: x.value_counts().index[-1])\n",
    "locationG['wkendRatio'] = location.groupby('place_id')['isWeekend'].mean()\n",
    "locationG['place_id'] = locationG.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108390, 6)\n"
     ]
    }
   ],
   "source": [
    "print locationG.shape\n",
    "pickle.dump(locationG, open('features_time.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/yingjiang/Dropbox/Learnings/Stats_data/Projects/FBCheckins'\n",
    "os.chdir(path)\n",
    "features = pickle.load(open('features.p', 'rb'))\n",
    "features0 = pickle.load(open('features0.p', 'rb'))\n",
    "features1 = pickle.load(open('features1.p', 'rb'))\n",
    "features2 = pickle.load(open('features2.p', 'rb'))\n",
    "features3 = pickle.load(open('features3.p', 'rb'))\n",
    "features4 = pickle.load(open('features4.p', 'rb'))\n",
    "features = pd.concat([features, features0, features1, features2, features3, features4])\n",
    "\n",
    "features = features.reset_index(range(features.shape[0]))\n",
    "pickle.dump(features, open('features_loc.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresAll = pd.merge(features, locationG, on = 'place_id', how = 'inner')\n",
    "pickle.dump(featuresAll, open('features_all.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91073, 2)\n",
      "(91073,)\n"
     ]
    }
   ],
   "source": [
    "trainX = features[['meanStd_x', 'meanStd_y']]\n",
    "trainY = features.place_id\n",
    "print trainX.shape\n",
    "print trainY.shape\n",
    "\n",
    "print trainX.meanStd_x.isnull().sum()\n",
    "print trainX.meanStd_y.isnull().sum()\n",
    "print trainX.meanStd_x.index[trainX.meanStd_x.apply(np.isnan)]\n",
    "print trainX.meanStd_y.index[trainX.meanStd_y.apply(np.isnan)]\n",
    "\n",
    "trainX = trainX.dropna()\n",
    "trainY = trainY.drop(trainY.index[[89497]])\n",
    "print trainX.shape\n",
    "print trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108018, 4)\n",
      "(108018,)\n"
     ]
    }
   ],
   "source": [
    "featuresAll = pickle.load(open('features_all.p', 'rb'))\n",
    "featuresAll = featuresAll.dropna()\n",
    "trainX_time = featuresAll[['meanStd_x', 'meanStd_y', 'hrHiFreq', 'dayHiFreq']]\n",
    "# trainX_time = trainX_time.dropna()\n",
    "trainY_time = featuresAll.place_id\n",
    "print trainX_time.shape\n",
    "print trainY_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8607230, 5)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(path + '/test.csv')\n",
    "testX = test[['x', 'y']]\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8607230, 4)\n"
     ]
    }
   ],
   "source": [
    "# testX_time = test[['x', 'y']]\n",
    "# testX_time['time'] = pd.to_datetime(test.time, unit = 'm')\n",
    "# testX_time['hour'] = testX_time.time.apply(lambda x: datetime.datetime.strptime(str(x)[11:], \"%H:%M:%S\").hour)\n",
    "# testX_time['weekday'] = testX_time.time.apply(lambda x: x.dayofweek)\n",
    "# testX_time['hour'] = testX_time.time.apply(extractHr)\n",
    "# testX_time['weekday'] = testX_time.time.apply(extractDay)\n",
    "\n",
    "testX_time = testX_time.drop('time', axis = 1)\n",
    "print testX_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1675</td>\n",
       "      <td>1.3608</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.3909</td>\n",
       "      <td>2.5301</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0978</td>\n",
       "      <td>2.3473</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9990</td>\n",
       "      <td>1.0591</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6670</td>\n",
       "      <td>9.7254</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x       y  hour  weekday\n",
       "0  0.1675  1.3608    10        5\n",
       "1  7.3909  2.5301     3        0\n",
       "2  8.0978  2.3473    10        2\n",
       "3  0.9990  1.0591     1        3\n",
       "4  0.6670  9.7254    23        0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(trainX_time, trainY_time) \n",
    "testY = knn.predict(testX_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8607230"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testY2 = pd.DataFrame(\n",
    "    {\n",
    "        \"place_id\": testY\n",
    "                   \n",
    "}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testY2.to_csv('FBCheckin_test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
